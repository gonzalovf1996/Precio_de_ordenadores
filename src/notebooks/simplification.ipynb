{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'Company', 'Product', 'TypeName', 'Inches',\n",
       "       'ScreenResolution', 'Cpu', 'Ram', 'Memory', 'Gpu', 'OpSys', 'Weight',\n",
       "       'Price_euros', '2 in 1 Convertible', 'Gaming', 'Netbook', 'Notebook',\n",
       "       'Ultrabook', 'Workstation', 'Touchscreen', 'High_resolucion',\n",
       "       'Chrome OS', 'Linux', 'Mac OS X', 'No OS', 'Windows 10', 'Windows 10 S',\n",
       "       'Windows 7', 'macOS', 'Intel Core i3', 'Intel Core i5', 'Intel Core i7',\n",
       "       'Intel Celeron Dual Core', 'Intel Pentium Quad Core', 'A4', 'A6', 'A8',\n",
       "       'A10', 'A12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos los datos\n",
    "\n",
    "train = pd.read_csv(r'datos/train_tratado.csv')\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplificamos el modelo\n",
    "\n",
    "En primer lugar, vemos que no hay overfitting, por tanto la regularización ni la carga polinómica mejoran el modelo. Por ende, veremos si hay underfitting y podemos mejorar el modelo.\n",
    "\n",
    "Cierta multicolinearidad presente en dos columnas ('2 in 1 Convertible' & 'Touchscreen' ). Por ende, como '2 in 1 Convertible' tiene menor correlación con nuestra target, la borramos del dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a supersimplificar\n",
    "\n",
    "El punto óptimo de menor error en test es cuando consideramos únicamente las variables que afectan en nuestra predicción en más del 9%, que acorde a la matriz de correlación son:\n",
    "- Ram (0.74)\n",
    "- Notebook (-0.53)\n",
    "- Gaming (0.37)\n",
    "- High_resolution (0.36)\n",
    "- Ultrabook (0.24)\n",
    "- Weight (0.24)\n",
    "- Workstation (0.23)\n",
    "- Touchscreen (0.21)\n",
    "- Memory (0.14)\n",
    "- Netbook (-0.12)\n",
    "- Chrome OS (-0.13)\n",
    "- Linux (-0.16)\n",
    "- No OS (-0.17)\n",
    "- Windows 10 (0.12)\n",
    "- Windows 7 (0.14)\n",
    "- macOS (0.091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['Ram', 'Memory', 'Weight',\n",
    "       'Gaming', 'Netbook', 'Notebook',\n",
    "       'Ultrabook', 'Workstation', 'Touchscreen', 'High_resolucion',\n",
    "       'Chrome OS', 'Linux', 'No OS', 'Windows 10', \n",
    "       'Windows 7', 'macOS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 267.8734113108484\n",
      "Test MAE: 264.95371728384\n",
      "\n",
      "Train MAPE: 0.26046521718589616\n",
      "Test MAPE: 0.27629252239254387\n",
      "\n",
      "Train MSE: 151926.15162693337\n",
      "Test MSE: 143743.86350683094\n",
      "\n",
      "Train RMSE: 389.7770537460272\n",
      "Test RMSE: 379.13567954866886\n",
      "\n",
      "Train score 0.7054922259040936\n",
      "Test score 0.7080447575043263\n"
     ]
    }
   ],
   "source": [
    "X = train[['Ram', 'Memory', 'Weight',\n",
    "       'Gaming', 'Netbook', 'Notebook',\n",
    "       'Ultrabook', 'Workstation', 'Touchscreen', 'High_resolucion',\n",
    "       'Chrome OS', 'Linux', 'No OS', 'Windows 10', \n",
    "       'Windows 7', 'macOS', 'Intel Core i3', 'Intel Core i5', 'Intel Core i7',\n",
    "       'Intel Celeron Dual Core', 'Intel Pentium Quad Core', 'A4', 'A6', 'A8',\n",
    "       'A10', 'A12']]\n",
    "\n",
    "\n",
    "\n",
    "y = train['Price_euros']\n",
    "\n",
    "# Separamos X_train y X_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#creating LinearRegression Object\n",
    "model = LinearRegression()\n",
    "\n",
    "#Training the Data Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Calculamos los errores\n",
    "print('Train MAE:', metrics.mean_absolute_error(y_train, model.predict(X_train)))\n",
    "print('Test MAE:', metrics.mean_absolute_error(y_test, model.predict(X_test)))\n",
    "print(\"\")\n",
    "print('Train MAPE:', metrics.mean_absolute_percentage_error(y_train, model.predict(X_train)))\n",
    "print('Test MAPE:', metrics.mean_absolute_percentage_error(y_test, model.predict(X_test)))\n",
    "print(\"\")\n",
    "print('Train MSE:', metrics.mean_squared_error(y_train, model.predict(X_train)))\n",
    "print('Test MSE:', metrics.mean_squared_error(y_test, model.predict(X_test)))\n",
    "print(\"\")\n",
    "print('Train RMSE:', np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))))\n",
    "print('Test RMSE:', np.sqrt(metrics.mean_squared_error(y_test, model.predict(X_test))))\n",
    "print(\"\")\n",
    "print('Train score', model.score(X_train, y_train))\n",
    "print('Test score', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluamos con los datos del data set de tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = pd.read_csv(\"Datos/test_tratado.csv\")\n",
    "\n",
    "X_pred_1 = X_pred[['Ram', 'Memory', 'Weight',\n",
    "       'Gaming', 'Netbook', 'Notebook',\n",
    "       'Ultrabook', 'Workstation', 'Touchscreen', 'High_resolucion',\n",
    "       'Chrome OS', 'Linux', 'No OS', 'Windows 10', \n",
    "       'Windows 7', 'macOS', 'Intel Core i3', 'Intel Core i5', 'Intel Core i7',\n",
    "       'Intel Celeron Dual Core', 'Intel Pentium Quad Core', 'A4', 'A6', 'A8',\n",
    "       'A10', 'A12']]\n",
    "\n",
    "predictions = model.predict(X_pred_1)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "submission = pd.DataFrame(X_pred['id'].copy())\n",
    "submission['Price_euros'] = predictions[0].copy()\n",
    "\n",
    "submission.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasamos el check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "sample = pd.read_csv(\"Datos/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aún no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\n",
    "    \"\"\"\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id.all() == sample.id.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                submission.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "# chequeator(submission)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c476fdca1fa146c1aa9930d737fa2969289d4717133eb1043d72ac40501f9294"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
